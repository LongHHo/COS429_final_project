{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of SMobileNetV2 fixed-lr.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDgWioWyKgRy",
        "outputId": "73c426ae-ef33-4295-80ba-f8a493e83e84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/final_proj"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7sqo7o1Kk2T",
        "outputId": "af678d9e-13b9-49f7-803f-005d8f2a5040"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1YMOPkl5pAMR5Y440QTaZiAbd1YXrDEUb/final_proj\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hShJQFiKDrEZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e28a8281-e530-4067-868e-40a48c6175ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import numpy.random as rng\n",
        "from tensorflow.keras import layers, models\n",
        "from keras import backend as K\n",
        "from keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "bcFh9QqPIeCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_in = open(\"mini-imagenet-cache-train.pkl\", \"rb\")\n",
        "train = pickle.load(train_in)\n",
        "ungrouped_Xtrain = train[\"image_data\"]\n",
        "val_in = open(\"mini-imagenet-cache-val.pkl\", \"rb\")\n",
        "val = pickle.load(val_in)\n",
        "ungrouped_Xval = val[\"image_data\"]"
      ],
      "metadata": {
        "id": "hREn6mqJJwBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mean = ungrouped_Xtrain.mean(axis=(0,1,2)) \n",
        "train_std = ungrouped_Xtrain.std(axis=(0,1,2))\n",
        "\n",
        "ungrouped_Xtrain = ungrouped_Xtrain.astype('float32')\n",
        "ungrouped_Xval = ungrouped_Xval.astype('float32')"
      ],
      "metadata": {
        "id": "44rm3Y15KHv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ungrouped_Xtrain -= train_mean\n",
        "ungrouped_Xtrain /= train_std\n",
        "ungrouped_Xval -= train_mean\n",
        "ungrouped_Xval /= train_std"
      ],
      "metadata": {
        "id": "WyELYGaHL4-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = ungrouped_Xtrain.reshape([64, 600, 84, 84, 3])\n",
        "val_data = ungrouped_Xval.reshape([16, 600, 84, 84, 3])\n",
        "train_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoJdNKVhKa43",
        "outputId": "d1cca136-c273-413a-fb1b-17036211fb7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64, 600, 84, 84, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pairwise_batch(batch_size, train_data, input_shape):\n",
        "    \"\"\"\n",
        "    Create batch of n pairs, half same class, half different class\n",
        "    \"\"\"\n",
        "    n_classes, n_examples, w, h, d = train_data.shape\n",
        "    new_w, new_h, new_d = input_shape\n",
        "    \n",
        "\n",
        "    rng = np.random.default_rng()\n",
        "\n",
        "    # randomly sample several classes to use in the batch\n",
        "    categories = rng.choice(n_classes,size=(batch_size,))\n",
        "    \n",
        "    # initialize 2 empty arrays for the input image batch\n",
        "    pairs=[np.zeros((batch_size, new_w, new_h, new_d)) for i in range(2)]\n",
        "    \n",
        "    # initialize vector for the targets\n",
        "    targets=np.zeros((batch_size,))\n",
        "    \n",
        "    # make one half of it '1's, so 2nd half of batch has same class\n",
        "    targets[batch_size//2:] = 1\n",
        "    for i in range(batch_size):\n",
        "        category = categories[i]\n",
        "        idx_1 = np.random.randint(0, n_examples)\n",
        "        pairs[0][i,:,:,:] = tf.image.resize(train_data[category, idx_1].reshape(w, h, d), (224, 224)).numpy()\n",
        "        idx_2 = np.random.randint(0, n_examples)\n",
        "        \n",
        "        # pick images of same class for 1st half, different for 2nd\n",
        "        if i >= batch_size // 2:\n",
        "            category_2 = category  \n",
        "        else: \n",
        "            # add a random number to the category modulo n classes to ensure 2nd image has a different category\n",
        "            category_2 = (category + np.random.randint(1,n_classes)) % n_classes\n",
        "        \n",
        "        pairs[1][i,:,:,:] = tf.image.resize(train_data[category_2,idx_2].reshape(w, h, d), (224, 224)).numpy()\n",
        "    \n",
        "    return pairs, targets\n",
        "\n",
        "\n",
        "def data_generator(data, batch_size, input_shape):\n",
        "    while True:\n",
        "        (inputs,targets) = get_pairwise_batch(batch_size, train_data, input_shape)\n",
        "        yield inputs, targets"
      ],
      "metadata": {
        "id": "bEjYScBNIb-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fn_loss(margin=1):\n",
        "    \"\"\"Provides 'constrastive_loss' an enclosing scope with variable 'margin'.\n",
        "\n",
        "  Arguments:\n",
        "      margin: Integer, defines the baseline for distance for which pairs\n",
        "              should be classified as dissimilar. - (default is 1).\n",
        "\n",
        "  Returns:\n",
        "      'constrastive_loss' function with data ('margin') attached.\n",
        "  \"\"\"\n",
        "\n",
        "    # Contrastive loss = mean( (1-true_value) * square(prediction) +\n",
        "    #                         true_value * square( max(margin-prediction, 0) ))\n",
        "    def contrastive_loss(y, preds):\n",
        "      # explicitly cast the true class label data type to the predicted\n",
        "      # class label data type (otherwise we run the risk of having two\n",
        "      # separate data types, causing TensorFlow to error out)\n",
        "      y = tf.cast(y, preds.dtype)\n",
        "      # calculate the contrastive loss between the true labels and\n",
        "      # the predicted labels\n",
        "      squaredPreds = K.square(preds)\n",
        "      squaredMargin = K.square(K.maximum(margin - preds, 0))\n",
        "      loss = K.mean(y * squaredPreds + (1 - y) * squaredMargin)\n",
        "      # return the computed contrastive loss to the calling function\n",
        "      return loss\n",
        "\n",
        "    return contrastive_loss"
      ],
      "metadata": {
        "id": "sB1eFFhjJCo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def L2_Norm(vectors):\n",
        "    # unpack the vectors into separate lists\n",
        "    (featsA, featsB) = vectors\n",
        "    # compute the sum of squared distances between the vectors\n",
        "    sumSquared = K.sum(K.square(featsA - featsB), axis=1,\n",
        "      keepdims=True)\n",
        "    # return the euclidean distance between the vectors\n",
        "    return K.sqrt(K.maximum(sumSquared, K.epsilon()))"
      ],
      "metadata": {
        "id": "lHj_moaJLX02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BottleneckResidualBlock(layers.Layer):\n",
        "  def __init__(self, expansion_factor, channels, stride, name=None, trainable=True):\n",
        "    super(BottleneckResidualBlock, self).__init__(name=name, trainable=trainable)\n",
        "    self.expansion_factor = expansion_factor\n",
        "    self.channels = channels\n",
        "    self.stride = stride\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    input_channels = input_shape[3]\n",
        "    self.c1 = layers.Conv2D(filters=self.expansion_factor*input_channels, kernel_size=(1,1), use_bias=False)\n",
        "    self.dc1 = layers.DepthwiseConv2D(kernel_size=(3,3), strides=self.stride, use_bias=False, padding='same')\n",
        "    self.c2 = layers.Conv2D(filters=self.channels, kernel_size=(1,1), use_bias=False)\n",
        "\n",
        "    self.bn1 = layers.BatchNormalization()\n",
        "    self.bn2 = layers.BatchNormalization()\n",
        "    self.bn3 = layers.BatchNormalization()\n",
        "\n",
        "  def call(self, inputs, training=False):\n",
        "    x = self.c1(inputs)\n",
        "    x = tf.nn.relu6(x)\n",
        "    x = self.bn1(x, training=training)\n",
        "\n",
        "    x = self.dc1(x)\n",
        "    x = tf.nn.relu6(x)\n",
        "    x = self.bn2(x, training=training)\n",
        "    \n",
        "    x = self.c2(x)\n",
        "    x = self.bn3(x, training=training)\n",
        "    \n",
        "    if self.stride == 1 and x.shape[1:] == inputs.shape[1:]:\n",
        "      x += inputs\n",
        "\n",
        "    return x\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super().get_config()\n",
        "    config.update({\n",
        "        \"expansion_factor\": self.expansion_factor,\n",
        "        \"channels\": self.channels,\n",
        "        \"stride\": self.stride,\n",
        "    })\n",
        "    return config"
      ],
      "metadata": {
        "id": "N4wGBuSQUeQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (224, 224, 3)\n",
        "input_l = layers.Input(input_shape)\n",
        "input_r = layers.Input(input_shape)\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), strides=2, padding='same', activation=tf.nn.relu6, input_shape=input_shape))\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "# bottleneck 1\n",
        "model.add(BottleneckResidualBlock(1, 16, 1))\n",
        "# bottleneck 2\n",
        "model.add(BottleneckResidualBlock(6, 24, 2))\n",
        "model.add(BottleneckResidualBlock(6, 24, 1))\n",
        "# bottleneck 3\n",
        "model.add(BottleneckResidualBlock(6, 32, 2))\n",
        "for i in range(2):\n",
        "  model.add(BottleneckResidualBlock(6, 32, 1))\n",
        "# bottleneck 4\n",
        "model.add(BottleneckResidualBlock(6, 64, 2))\n",
        "for i in range(3):\n",
        "  model.add(BottleneckResidualBlock(6, 64, 1))\n",
        "# bottleneck 5\n",
        "for i in range(3):\n",
        "  model.add(BottleneckResidualBlock(6, 96, 1))\n",
        "# bottleneck 6\n",
        "model.add(BottleneckResidualBlock(6, 160, 2))\n",
        "for i in range(2):\n",
        "  model.add(BottleneckResidualBlock(6, 160, 1))\n",
        "# bottleneck 7\n",
        "model.add(BottleneckResidualBlock(6, 320, 1))\n",
        "\n",
        "model.add(layers.Conv2D(1280, (1, 1), activation=tf.nn.relu6))\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "model.add(layers.AveragePooling2D((7, 7)))\n",
        "\n",
        "model.add(layers.Conv2D(1280, (1, 1), activation=tf.nn.relu6))\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "model.add(layers.GlobalAveragePooling2D())\n",
        "model.add(layers.Dropout(0.1))\n",
        "\n",
        "encoded_l = model(input_l)\n",
        "encoded_r = model(input_r)\n",
        "\n",
        "L2_distance = layers.Lambda(L2_Norm)([encoded_l, encoded_r])\n",
        "model = Model(inputs=[input_l,input_r],outputs=L2_distance)"
      ],
      "metadata": {
        "id": "Bge3XG_OXOzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FW7NZu1nXmN9",
        "outputId": "3ed80ef9-dfb7-4b72-95ec-64c4b2346986"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " sequential (Sequential)        (None, 1280)         3905248     ['input_1[0][0]',                \n",
            "                                                                  'input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 1)            0           ['sequential[0][0]',             \n",
            "                                                                  'sequential[1][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3,905,248\n",
            "Trainable params: 3,868,512\n",
            "Non-trainable params: 36,736\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyper params\n",
        "lr = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.045,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.98)\n",
        "momentum = 0.9\n",
        "margin = 1"
      ],
      "metadata": {
        "id": "PNUzf7nEJH2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyper parameters\n",
        "evaluate_every = 1000  # interval for evaluating on one-shot tasks\\\n",
        "# download_every = 1000\n",
        "batch_size = 64\n",
        "n_iter = 10000 # No. of training iterations\n",
        "\n",
        "# used for one batching testing\n",
        "N_way = 10 # how many classes for testing one-shot tasks. has to be less than num classes in dataset\n",
        "n_val = 250 # how many one-shot tasks to validate on\n",
        "\n",
        "# used for straight validation testing\n",
        "val_batch_size = 64\n",
        "\n",
        "val_test_size = 8000\n",
        "\n",
        "best = -1\n",
        "\n",
        "steps_per_epoch = 1000\n",
        "epochs = 10"
      ],
      "metadata": {
        "id": "KQl2ZvFMJSH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = RMSprop(learning_rate = lr, momentum=momentum)\n",
        "model.compile(loss=fn_loss(margin=margin),optimizer=optimizer)"
      ],
      "metadata": {
        "id": "zEaM57eFJKKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    data_generator(train_data, batch_size, (224, 224, 3)),\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_data = data_generator(val_data, val_batch_size, (224, 224, 3)),\n",
        "    validation_steps = 10,\n",
        "    epochs=epochs, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZDjceSQkd6C",
        "outputId": "42c2fec0-5312-4fb3-9f69-d401cdd038f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 2127s 2s/step - loss: 5.4544 - val_loss: 35223.2031\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 2095s 2s/step - loss: 0.5461 - val_loss: 32063.0664\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 2099s 2s/step - loss: 0.3492 - val_loss: 186053.9062\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 2098s 2s/step - loss: 0.3474 - val_loss: 113805.3359\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 2098s 2s/step - loss: 0.3477 - val_loss: 428352.3438\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 2090s 2s/step - loss: 0.3727 - val_loss: 85758.4219\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 2078s 2s/step - loss: 0.3483 - val_loss: 1140857.7500\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 2087s 2s/step - loss: 0.3459 - val_loss: 454497.0625\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 2091s 2s/step - loss: 0.3467 - val_loss: 257163.5312\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 2091s 2s/step - loss: 0.3460 - val_loss: 298233.2812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = './weights/'\n",
        "model_name = \"mobilenet_contrastive_2\""
      ],
      "metadata": {
        "id": "if3CPH-EI0RU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights(os.path.join(model_path, 'weights_{}.h5'.format(model_name)))"
      ],
      "metadata": {
        "id": "2H5StTQpIo_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SNZORc48FDmq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}